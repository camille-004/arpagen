{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1392cccf",
   "metadata": {},
   "source": [
    "Run this if nltk not installed in kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6892b1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375160d4",
   "metadata": {},
   "source": [
    "Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a0f9b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import json\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a48f21a",
   "metadata": {},
   "source": [
    "Arpabet Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3c8054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/33666557/get-phonemes-from-any-word-in-python-nltk-or-other-modules\n",
    "#Set arpabet to nltk cmudict corpus. If cmudict unavalible, download it then set.\n",
    "try:\n",
    "    arpabet = nltk.corpus.cmudict.dict()\n",
    "except LookupError:\n",
    "    nltk.download('cmudict')\n",
    "    arpabet = nltk.corpus.cmudict.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a56579",
   "metadata": {},
   "source": [
    "Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21e32eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define translation from word to phonetics\n",
    "# If word not in cmudict dictionary, find closest match (SequenceMatcher)\n",
    "def word_to_phonetic(arpabet, word):\n",
    "    word = word.lower()\n",
    "    try:\n",
    "        phonetic = arpabet[word]\n",
    "    except:\n",
    "        keys = arpabet.keys()\n",
    "        how_similar = [SequenceMatcher(None, word, key).ratio() for key in keys]\n",
    "        max_index = how_similar.index(max(how_similar))\n",
    "        phonetic = list(arpabet.values())[max_index]\n",
    "    if type(phonetic) == list:\n",
    "        phonetic = phonetic[0]\n",
    "    return phonetic\n",
    "\n",
    "\n",
    "# Define translation from phonetics to words\n",
    "# If word not in cmudict dictionary, find closest match (SequenceMatcher)\n",
    "def phonetic_to_word(arpabet, phonemes):\n",
    "    try:\n",
    "        word = list(arpabet.keys())[list(arpabet.values()).index(phonemes)]\n",
    "    except:\n",
    "        phonemes = phonemes[0]\n",
    "        values = arpabet.values()\n",
    "        how_similar = [SequenceMatcher(None, phonemes, value[0]).ratio() for value in values]\n",
    "        max_index = how_similar.index(max(how_similar))\n",
    "        word = list(arpabet.keys())[max_index]\n",
    "        if type(word) == list:\n",
    "            word = word[0]\n",
    "    return word\n",
    "\n",
    "\n",
    "# Pre-processing of *.txt into sentences\n",
    "def text_to_sentences(data, split_str, remove_chars, r, toLowerCase = True):\n",
    "    data = re.split(split_str, data)\n",
    "    data = [d.replace('\\n', ' ') for d in data]\n",
    "    data = [re.sub(remove_chars, '', d) for d in data]\n",
    "    if toLowerCase:\n",
    "        data = [d.lower() for d in data]\n",
    "    data = [\" \".join([i for i in d.split(' ') if i]) for d in data]\n",
    "    data = [d for d in data if len(d) >= r[0] and len(d) <= r[1]]\n",
    "    uniqueChars = set(' '.join(data))\n",
    "    return (data, len(uniqueChars))\n",
    "\n",
    "\n",
    "# Convert list of sentence to list of phoneme lists\n",
    "def sentences_to_phonemes(arpabet, data, print_every, of):\n",
    "    data = [([word_to_phonetic(arpabet, word) for word in d.split(' ')],\n",
    "             (print(\"Line:\", i, \"of\", of) if i % print_every == 0 else '')) for i, d in enumerate(data, 1)]\n",
    "    return list(zip(*data))[0]\n",
    "\n",
    "\n",
    "# Convert list of phoneme lists to sentences\n",
    "def phonemes_to_sentences(arpabet, data, print_every, of):\n",
    "    data = [(' '.join([phonetic_to_word(arpabet, [p]) for p in d]),\n",
    "             (print(\"Line:\", i, \"of\", of) if i % print_every == 0 else '')) for i, d in enumerate(data, 1)]\n",
    "    return list(zip(*data))[0]\n",
    "\n",
    "\n",
    "# Output phonemes in json format\n",
    "def to_json(jsonOutput_name, data):\n",
    "    data_as_dict = {\"Sentence \"+str(i+1):{\"Word \"+str(l+1):{\"Phoneme \"+str(m+1):n for (m, n) in enumerate(k)} for (l, k) in enumerate(j)} for (i, j) in enumerate(data)}\n",
    "    jsonOutput = open(jsonOutput_name, \"w\")\n",
    "    jsonOutput.write(json.dumps(data_as_dict, indent=4))\n",
    "    jsonOutput.close()\n",
    "\n",
    "    \n",
    "# Import phonemes from json format\n",
    "def from_json(jsonInput_file):\n",
    "    data = json.load(open(jsonInput_file))\n",
    "    data = [[list(n.values()) for n in list(m.values())] for m in list(data.values())]\n",
    "    return tuple(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de736373",
   "metadata": {},
   "source": [
    "English/Phonetics Translation Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b8de895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biggest => ['B', 'IH1', 'G', 'AH0', 'S', 'T']\n",
      "bigests => ['B', 'IH1', 'G', 'AH0', 'S', 'T']\n",
      "[['B', 'IH1', 'G', 'AH0', 'S', 'T']] => biggest\n",
      "[['B', 'IH1', 'G', 'AH0', 'S', 'G']] => biggest\n"
     ]
    }
   ],
   "source": [
    "#Get phonetics of word in dictionary\n",
    "w = \"biggest\"\n",
    "p = word_to_phonetic(arpabet, w)\n",
    "print(w, \"=>\",p)\n",
    "#Get closest phonetics of word NOT in dictionary\n",
    "w = \"bigests\"\n",
    "p = word_to_phonetic(arpabet, w)\n",
    "print(w, \"=>\",p)\n",
    "#Get word of phonetics in dictionary\n",
    "p = [['B', 'IH1', 'G', 'AH0', 'S', 'T']]\n",
    "w = phonetic_to_word(arpabet, p)\n",
    "print(p, \"=>\",w)\n",
    "#Get closest word of phonetics NOT in dictionary\n",
    "p = [['B', 'IH1', 'G', 'AH0', 'S', 'G']]\n",
    "w = phonetic_to_word(arpabet, p)\n",
    "print(p, \"=>\",w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997a1980",
   "metadata": {},
   "source": [
    "\\*.txt processing Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f448157a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in book: 5\n",
      "Number of unique characters: 27\n",
      "Example sentence: the old testament of the king james version of the bible\n",
      "----- Transcribing sentences to phonemes -----\n",
      "Line: 1 of 5\n",
      "Line: 2 of 5\n",
      "Line: 3 of 5\n",
      "Line: 4 of 5\n",
      "Line: 5 of 5\n",
      "Example phonetic transcription: [['DH', 'AH0'], ['OW1', 'L', 'D'], ['T', 'EH1', 'S', 'T', 'AH0', 'M', 'AH0', 'N', 'T'], ['AH1', 'V'], ['DH', 'AH0'], ['K', 'IH1', 'NG'], ['JH', 'EY1', 'M', 'Z'], ['V', 'ER1', 'ZH', 'AH0', 'N'], ['AH1', 'V'], ['DH', 'AH0'], ['B', 'AY1', 'B', 'AH0', 'L']]\n",
      "----- Transcribing phonemes to sentences -----\n",
      "Line: 1 of 5\n",
      "Line: 2 of 5\n",
      "Line: 3 of 5\n",
      "Line: 4 of 5\n",
      "Line: 5 of 5\n",
      "Example English transcription: the old testament of the king james version of the bible\n",
      "Export/import path matches original values:  True\n"
     ]
    }
   ],
   "source": [
    "# Open *.txt file\n",
    "file = open(\"bible.txt\")\n",
    "# Process *.txt file into list of sentences, and obtain number of unique characters\n",
    "# text_to_sentences(str, regex sentence split chars, regex whitelist chars, acceptable sentence range, toLower)\n",
    "# Here, sentence splits specified as .?! and \\n with uppercase following, whitelist only letters, remove any sentences\n",
    "# of fewer than 10 or more than 100 letters (including spaces), and converts final array to all lowercase.\n",
    "data, unique_chars = \\\n",
    "    text_to_sentences(file.read(), '\\.|\\!|\\?|\\n(?=[A-Z])', r'[^a-zA-Z ]+', (10, 100), toLowerCase = True)\n",
    "# For illustration purposes, only use first 10 lines from here on\n",
    "data = data[0:5]\n",
    "r = 4 #random.randint(0, len(data))\n",
    "# Print some stuff\n",
    "print(\"Number of sentences in book:\", len(data))\n",
    "print(\"Number of unique characters:\", unique_chars)\n",
    "print(\"Example sentence:\", data[r]) #random.choice(data))\n",
    "# Get phonetic transcriptions of sentences\n",
    "print(\"----- Transcribing sentences to phonemes -----\")\n",
    "p = sentences_to_phonemes(arpabet, data, 1, len(data))\n",
    "print(\"Example phonetic transcription:\", p[r])\n",
    "# Get English equivilents of phonetic transcription\n",
    "print(\"----- Transcribing phonemes to sentences -----\")\n",
    "s = phonemes_to_sentences(arpabet, p, 1, len(data))\n",
    "print(\"Example English transcription:\", s[r])\n",
    "# close file\n",
    "file.close()\n",
    "\n",
    "# Output Phonetic transcriptions p to 'example.json'\n",
    "to_json(\"example.json\", p)\n",
    "# Import Phonetic transcriptions from 'example.json'\n",
    "f = from_json('example.json')\n",
    "# Compare f and p to confirm to_json/from_json works as intended\n",
    "print(\"Export/import path matches original values: \", f == p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7941b6",
   "metadata": {},
   "source": [
    "Now, process entire bible.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d60722bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in book: 17326\n",
      "Number of unique characters: 27\n",
      "----- Transcribing sentences to phonemes -----\n",
      "Line: 100 of 17326\n",
      "Line: 200 of 17326\n",
      "Line: 300 of 17326\n",
      "Line: 400 of 17326\n",
      "Line: 500 of 17326\n",
      "Line: 600 of 17326\n",
      "Line: 700 of 17326\n",
      "Line: 800 of 17326\n",
      "Line: 900 of 17326\n",
      "Line: 1000 of 17326\n",
      "Line: 1100 of 17326\n",
      "Line: 1200 of 17326\n",
      "Line: 1300 of 17326\n",
      "Line: 1400 of 17326\n",
      "Line: 1500 of 17326\n",
      "Line: 1600 of 17326\n",
      "Line: 1700 of 17326\n",
      "Line: 1800 of 17326\n",
      "Line: 1900 of 17326\n",
      "Line: 2000 of 17326\n",
      "Line: 2100 of 17326\n",
      "Line: 2200 of 17326\n",
      "Line: 2300 of 17326\n",
      "Line: 2400 of 17326\n",
      "Line: 2500 of 17326\n",
      "Line: 2600 of 17326\n",
      "Line: 2700 of 17326\n",
      "Line: 2800 of 17326\n",
      "Line: 2900 of 17326\n",
      "Line: 3000 of 17326\n",
      "Line: 3100 of 17326\n",
      "Line: 3200 of 17326\n",
      "Line: 3300 of 17326\n",
      "Line: 3400 of 17326\n",
      "Line: 3500 of 17326\n",
      "Line: 3600 of 17326\n",
      "Line: 3700 of 17326\n",
      "Line: 3800 of 17326\n",
      "Line: 3900 of 17326\n",
      "Line: 4000 of 17326\n",
      "Line: 4100 of 17326\n",
      "Line: 4200 of 17326\n",
      "Line: 4300 of 17326\n",
      "Line: 4400 of 17326\n",
      "Line: 4500 of 17326\n",
      "Line: 4600 of 17326\n",
      "Line: 4700 of 17326\n",
      "Line: 4800 of 17326\n",
      "Line: 4900 of 17326\n",
      "Line: 5000 of 17326\n",
      "Line: 5100 of 17326\n",
      "Line: 5200 of 17326\n",
      "Line: 5300 of 17326\n",
      "Line: 5400 of 17326\n",
      "Line: 5500 of 17326\n",
      "Line: 5600 of 17326\n",
      "Line: 5700 of 17326\n",
      "Line: 5800 of 17326\n",
      "Line: 5900 of 17326\n",
      "Line: 6000 of 17326\n",
      "Line: 6100 of 17326\n",
      "Line: 6200 of 17326\n",
      "Line: 6300 of 17326\n",
      "Line: 6400 of 17326\n",
      "Line: 6500 of 17326\n",
      "Line: 6600 of 17326\n",
      "Line: 6700 of 17326\n",
      "Line: 6800 of 17326\n",
      "Line: 6900 of 17326\n",
      "Line: 7000 of 17326\n",
      "Line: 7100 of 17326\n",
      "Line: 7200 of 17326\n",
      "Line: 7300 of 17326\n",
      "Line: 7400 of 17326\n",
      "Line: 7500 of 17326\n",
      "Line: 7600 of 17326\n",
      "Line: 7700 of 17326\n",
      "Line: 7800 of 17326\n",
      "Line: 7900 of 17326\n",
      "Line: 8000 of 17326\n",
      "Line: 8100 of 17326\n",
      "Line: 8200 of 17326\n",
      "Line: 8300 of 17326\n",
      "Line: 8400 of 17326\n",
      "Line: 8500 of 17326\n",
      "Line: 8600 of 17326\n",
      "Line: 8700 of 17326\n",
      "Line: 8800 of 17326\n",
      "Line: 8900 of 17326\n",
      "Line: 9000 of 17326\n",
      "Line: 9100 of 17326\n",
      "Line: 9200 of 17326\n",
      "Line: 9300 of 17326\n",
      "Line: 9400 of 17326\n",
      "Line: 9500 of 17326\n",
      "Line: 9600 of 17326\n",
      "Line: 9700 of 17326\n",
      "Line: 9800 of 17326\n",
      "Line: 9900 of 17326\n",
      "Line: 10000 of 17326\n",
      "Line: 10100 of 17326\n",
      "Line: 10200 of 17326\n",
      "Line: 10300 of 17326\n",
      "Line: 10400 of 17326\n",
      "Line: 10500 of 17326\n",
      "Line: 10600 of 17326\n",
      "Line: 10700 of 17326\n",
      "Line: 10800 of 17326\n",
      "Line: 10900 of 17326\n",
      "Line: 11000 of 17326\n",
      "Line: 11100 of 17326\n",
      "Line: 11200 of 17326\n",
      "Line: 11300 of 17326\n",
      "Line: 11400 of 17326\n",
      "Line: 11500 of 17326\n",
      "Line: 11600 of 17326\n",
      "Line: 11700 of 17326\n",
      "Line: 11800 of 17326\n",
      "Line: 11900 of 17326\n",
      "Line: 12000 of 17326\n",
      "Line: 12100 of 17326\n",
      "Line: 12200 of 17326\n",
      "Line: 12300 of 17326\n",
      "Line: 12400 of 17326\n",
      "Line: 12500 of 17326\n",
      "Line: 12600 of 17326\n",
      "Line: 12700 of 17326\n",
      "Line: 12800 of 17326\n",
      "Line: 12900 of 17326\n",
      "Line: 13000 of 17326\n",
      "Line: 13100 of 17326\n",
      "Line: 13200 of 17326\n",
      "Line: 13300 of 17326\n",
      "Line: 13400 of 17326\n",
      "Line: 13500 of 17326\n",
      "Line: 13600 of 17326\n",
      "Line: 13700 of 17326\n",
      "Line: 13800 of 17326\n",
      "Line: 13900 of 17326\n",
      "Line: 14000 of 17326\n",
      "Line: 14100 of 17326\n",
      "Line: 14200 of 17326\n",
      "Line: 14300 of 17326\n",
      "Line: 14400 of 17326\n",
      "Line: 14500 of 17326\n",
      "Line: 14600 of 17326\n",
      "Line: 14700 of 17326\n",
      "Line: 14800 of 17326\n",
      "Line: 14900 of 17326\n",
      "Line: 15000 of 17326\n",
      "Line: 15100 of 17326\n",
      "Line: 15200 of 17326\n",
      "Line: 15300 of 17326\n",
      "Line: 15400 of 17326\n",
      "Line: 15500 of 17326\n",
      "Line: 15600 of 17326\n",
      "Line: 15700 of 17326\n",
      "Line: 15800 of 17326\n",
      "Line: 15900 of 17326\n",
      "Line: 16000 of 17326\n",
      "Line: 16100 of 17326\n",
      "Line: 16200 of 17326\n",
      "Line: 16300 of 17326\n",
      "Line: 16400 of 17326\n",
      "Line: 16500 of 17326\n",
      "Line: 16600 of 17326\n",
      "Line: 16700 of 17326\n",
      "Line: 16800 of 17326\n",
      "Line: 16900 of 17326\n",
      "Line: 17000 of 17326\n",
      "Line: 17100 of 17326\n",
      "Line: 17200 of 17326\n",
      "Line: 17300 of 17326\n"
     ]
    }
   ],
   "source": [
    "file = open(\"bible.txt\")\n",
    "data, unique_chars = \\\n",
    "    text_to_sentences(file.read(), '\\.|\\!|\\?|\\n(?=[A-Z])', r'[^a-zA-Z ]+', (10, 100), toLowerCase = True)\n",
    "print(\"Number of sentences in book:\", len(data))\n",
    "print(\"Number of unique characters:\", unique_chars)\n",
    "print(\"----- Transcribing sentences to phonemes -----\")\n",
    "p = sentences_to_phonemes(arpabet, data, 100, len(data))\n",
    "file.close()\n",
    "to_json(\"bible.json\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe0028dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export/import path matches original values:  True\n"
     ]
    }
   ],
   "source": [
    "f = from_json('bible.json')\n",
    "print(\"Export/import path matches original values: \", f == p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fd46aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lign167",
   "language": "python",
   "name": "lign167"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
