{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1392cccf",
   "metadata": {},
   "source": [
    "Run this if nltk not installed in kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6892b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375160d4",
   "metadata": {},
   "source": [
    "Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0f9b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from difflib import SequenceMatcher\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a48f21a",
   "metadata": {},
   "source": [
    "Arpabet Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c8054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/33666557/get-phonemes-from-any-word-in-python-nltk-or-other-modules\n",
    "#Set arpabet to nltk cmudict corpus. If cmudict unavalible, download it then set.\n",
    "try:\n",
    "    arpabet = nltk.corpus.cmudict.dict()\n",
    "except LookupError:\n",
    "    nltk.download('cmudict')\n",
    "    arpabet = nltk.corpus.cmudict.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a56579",
   "metadata": {},
   "source": [
    "Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e32eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define translation from word to phonetics\n",
    "# If word not in cmudict dictionary, find closest match (SequenceMatcher)\n",
    "def word_to_phonetic(arpabet, word):\n",
    "    word = word.lower()\n",
    "    try:\n",
    "        phonetic = arpabet[word]\n",
    "    except:\n",
    "        keys = arpabet.keys()\n",
    "        how_similar = [SequenceMatcher(None, word, key).ratio() for key in keys]\n",
    "        max_index = how_similar.index(max(how_similar))\n",
    "        phonetic = list(arpabet.values())[max_index]\n",
    "    if type(phonetic) == list:\n",
    "        phonetic = phonetic[0]\n",
    "    return phonetic\n",
    "\n",
    "\n",
    "# Define translation from phonetics to words\n",
    "# If word not in cmudict dictionary, find closest match (SequenceMatcher)\n",
    "def phonetic_to_word(arpabet, phonemes):\n",
    "    try:\n",
    "        word = list(arpabet.keys())[list(arpabet.values()).index(phonemes)]\n",
    "    except:\n",
    "        phonemes = phonemes[0]\n",
    "        values = arpabet.values()\n",
    "        how_similar = [SequenceMatcher(None, phonemes, value[0]).ratio() for value in values]\n",
    "        max_index = how_similar.index(max(how_similar))\n",
    "        word = list(arpabet.keys())[max_index]\n",
    "        if type(word) == list:\n",
    "            word = word[0]\n",
    "    return word\n",
    "\n",
    "\n",
    "# Pre-processing of *.txt into sentences\n",
    "def text_to_sentences(data, split_str, remove_chars, r, toLowerCase = True):\n",
    "    data = re.split(split_str, data)\n",
    "    data = [d.replace('\\n', ' ') for d in data]\n",
    "    data = [re.sub(remove_chars, '', d) for d in data]\n",
    "    if toLowerCase:\n",
    "        data = [d.lower() for d in data]\n",
    "    data = [\" \".join([i for i in d.split(' ') if i]) for d in data]\n",
    "    data = [d for d in data if len(d) >= r[0] and len(d) <= r[1]]\n",
    "    uniqueChars = set(' '.join(data))\n",
    "    return (data, len(uniqueChars))\n",
    "\n",
    "\n",
    "# Convert list of sentence to list of phoneme lists\n",
    "def sentences_to_phonemes(arpabet, data, print_every, of):\n",
    "    data = [([word_to_phonetic(arpabet, word) for word in d.split(' ')],\n",
    "             (print(\"Line:\", i, \"of\", of) if i % print_every == 0 else '')) for i, d in enumerate(data, 1)]\n",
    "    return list(zip(*data))[0]\n",
    "\n",
    "\n",
    "# Convert list of phoneme lists to sentences\n",
    "def phonemes_to_sentences(arpabet, data, print_every, of):\n",
    "    data = [(' '.join([phonetic_to_word(arpabet, [p]) for p in d]),\n",
    "             (print(\"Line:\", i, \"of\", of) if i % print_every == 0 else '')) for i, d in enumerate(data, 1)]\n",
    "    return list(zip(*data))[0]\n",
    "\n",
    "\n",
    "# Output phonemes in json format\n",
    "def to_json(jsonOutput_name, data):\n",
    "    data_as_dict = {\"Sentence \"+str(i+1):{\"Word \"+str(l+1):{\"Phoneme \"+str(m+1):n for (m, n) in enumerate(k)} for (l, k) in enumerate(j)} for (i, j) in enumerate(data)}\n",
    "    jsonOutput = open(jsonOutput_name, \"w\")\n",
    "    jsonOutput.write(json.dumps(data_as_dict, indent=4))\n",
    "    jsonOutput.close()\n",
    "\n",
    "    \n",
    "# Import phonemes from json format\n",
    "def from_json(jsonInput_file):\n",
    "    data = json.load(open(jsonInput_file))\n",
    "    data = [[list(n.values()) for n in list(m.values())] for m in list(data.values())]\n",
    "    return tuple(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7941b6",
   "metadata": {},
   "source": [
    "Automatic processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60722bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_path = 'books'\n",
    "book_processed_path = 'books-processed'\n",
    "json_path = 'jsons'\n",
    "files = [book_path+'/'+str(f) for f in os.listdir(book_path) if f.endswith('.txt')]\n",
    "total_books = len(files)\n",
    "\n",
    "for i, f in enumerate(files):\n",
    "    file = open(f, encoding=\"utf8\")\n",
    "    book_name = os.path.basename(file.name).split(\".\")[0]\n",
    "    print(\"============ Processing book \"+str(i+1)+\" of \"+str(total_books)+\": \"+str(book_name)+\" ============\")\n",
    "    data, unique_chars = \\\n",
    "    text_to_sentences(file.read(), '\\.|\\!|\\?|\\n(?=[A-Z])', r'[^a-zA-Z ]+', (10, 200), toLowerCase = True)\n",
    "    print(\"Number of sentences in book: \"+str(len(data)))\n",
    "    book_processed = open(book_processed_path+'/'+book_name+\".txt\", \"w\")\n",
    "    book_processed.write(\"\\n\". join(data))\n",
    "    book_processed.close()\n",
    "    print(\"List of sentences saved in \"+book_processed_path+'/'+book_name+\".txt\")\n",
    "    p = sentences_to_phonemes(arpabet, data, 100, len(data))\n",
    "    file.close()\n",
    "    to_json(json_path+'/'+book_name+\".json\", p)\n",
    "    time.sleep(5)\n",
    "    p_from_file = from_json(json_path+'/'+book_name+\".json\")\n",
    "    print(\"Export/import path matches original values: \", p_from_file == p)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0028dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fd46aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd64a590",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lign167",
   "language": "python",
   "name": "lign167"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
