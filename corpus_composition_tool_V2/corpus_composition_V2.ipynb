{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d29ca21-48fb-469e-ac71-bd68ba108694",
   "metadata": {},
   "source": [
    "#### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ae1dbf2-c1b9-46e7-9647-a84dd34e65f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "from time import time\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.metrics.distance import jaccard_distance\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6476c1fb-df27-478a-bf9c-f7f273cf77e9",
   "metadata": {},
   "source": [
    "#### Arpabet Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "287d326a-bbe3-408e-a725-a41030d01b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/33666557/get-phonemes-from-any-word-in-python-nltk-or-other-modules\n",
    "#Set arpabet to nltk cmudict corpus. If cmudict unavalible, download it then set.\n",
    "try:\n",
    "    arpabet = nltk.corpus.cmudict.dict()\n",
    "except LookupError:\n",
    "    nltk.download('cmudict')\n",
    "    arpabet = nltk.corpus.cmudict.dict()\n",
    "\n",
    "#Keeping only the first set of phonemes\n",
    "for phoneme in arpabet: arpabet[phoneme] = arpabet[phoneme][0]\n",
    "\n",
    "accepted_words = list(arpabet.keys())\n",
    "accepted_phonemes = list(arpabet.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8c3aaa-cf49-41bd-b552-9630262362f2",
   "metadata": {},
   "source": [
    "#### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afa70d03-7e79-4efd-9a47-69de13ea3913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define translation from word to phonetics\n",
    "# If word not in cmudict dictionary, find closest match (Jaccard Distance)\n",
    "def word_to_phonetic(word):\n",
    "    try:\n",
    "        phonetic = arpabet[word]\n",
    "    except:\n",
    "        closest = [(jaccard_distance(set(ngrams(word, 2)),set(ngrams(w, 2))),w) for w in accepted_words if w[0]==word[0]]\n",
    "        phonetic = arpabet[min(closest, key = lambda d: d[0])[1]]\n",
    "    return phonetic\n",
    "\n",
    "# Define translation from phonetics to words\n",
    "# If word not in cmudict dictionary, find closest match (Jaccard Distance)\n",
    "def phonetic_to_word(phonemes):\n",
    "    try:\n",
    "        word = accepted_words[accepted_phonemes.index(phonemes)]\n",
    "    except:\n",
    "        closest = [(jaccard_distance(set(ngrams(phonemes, 2)),set(ngrams(w, 2))),w) for w in accepted_phonemes]\n",
    "        word = accepted_words[accepted_phonemes.index(min(closest, key = lambda t: t[0])[1])]\n",
    "    return word\n",
    "\n",
    "# Convert list of sentence to list of phoneme lists\n",
    "def sentences_to_phonemes(data):\n",
    "    return [sentence_to_phonemes(sentence) for sentence in tqdm(data)]\n",
    "\n",
    "def sentence_to_phonemes(sentence):\n",
    "    return [word_to_phonetic(word) for word in sentence.split(' ')]\n",
    "\n",
    "# Convert list of phoneme lists to sentences\n",
    "def phonemes_to_sentence(data):\n",
    "    return [phoneme_to_sentence(sentence) for sentence in tqdm(data)]\n",
    "\n",
    "def phoneme_to_sentence(phonemes):\n",
    "    return ' '.join([phonetic_to_word(phoneme) for phoneme in phonemes])\n",
    "\n",
    "# Pre-processing of *.txt into sentences\n",
    "def text_to_sentences(data, split_str='\\.|\\!|\\?', remove_chars=r'[^a-zA-Z ]+'):\n",
    "    data = re.split(split_str, data)\n",
    "    data = [d.replace('\\n', ' ') for d in data]\n",
    "    data = [re.sub(remove_chars, '', d.lower()).lstrip() for d in data]\n",
    "    data = [\" \".join(d.split()) for d in data if len(d) != 0]\n",
    "    return data\n",
    "\n",
    "# Output phonemes in json format\n",
    "def to_json(jsonOutput_name, data):\n",
    "    data_as_dict = {\"Sentence \"+str(i+1):{\"Word \"+str(l+1):{\"Phoneme \"+str(m+1):n for (m, n) in enumerate(k)} for (l, k) in enumerate(j)} for (i, j) in enumerate(data)}\n",
    "    jsonOutput = open(jsonOutput_name, \"w\")\n",
    "    jsonOutput.write(json.dumps(data_as_dict, indent=4))\n",
    "    jsonOutput.close()\n",
    "\n",
    "\n",
    "# Import phonemes from json format\n",
    "def from_json(jsonInput_file):\n",
    "    data = json.load(open(jsonInput_file))\n",
    "    data = [[list(n.values()) for n in list(m.values())] for m in list(data.values())]\n",
    "    return data\n",
    "\n",
    "def arpabet_recompiler(arpabet, data, export_file='arpabet.pkl'):\n",
    "    #Data preprocessing\n",
    "    data = data.replace('\\n', ' ')\n",
    "    data = re.sub(r'[^a-zA-Z ]+', '', data.lower())\n",
    "    data = re.split(' ', data)\n",
    "    data = [\" \".join(d.split()) for d in data if len(d) != 0]\n",
    "    \n",
    "    #Removing all unused arpabet words\n",
    "    arpabet_set, data_set = set(arpabet), set(data)\n",
    "    for word in tqdm(data_set - arpabet_set):\n",
    "        closest = [(jaccard_distance(set(ngrams(word, 2)),set(ngrams(w, 2))),w) for w in accepted_words if w[0]==word[0]]\n",
    "        data_set.add(min(closest, key = lambda d: d[0])[1])\n",
    "    for k in arpabet_set - data_set:\n",
    "        del arpabet[k]\n",
    "        \n",
    "    #Export new arpabet dictionary\n",
    "    file = open(export_file,\"wb\")\n",
    "    pickle.dump(arpabet,file)\n",
    "    file.close()\n",
    "    \n",
    "    return arpabet\n",
    "\n",
    "def arpabet_reader(import_file):\n",
    "    file = open(import_file, \"rb\")\n",
    "    arpabet = pickle.load(file)\n",
    "    file.close()\n",
    "    return arpabet, list(arpabet.keys()), list(arpabet.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d77fe65-1827-44de-a832-cdbd198e7b5e",
   "metadata": {},
   "source": [
    "#### English/Phonetics Translation Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56cd5bf6-72a4-4178-b46e-71d886124c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Recompiling Arpabet -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc3d690055b44b20af2e65ab40c779a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Transcribing sentences to phonemes -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba8ff8ed32c54181b573472333a41386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example phonetic transcription: [['IH0', 'N'], ['DH', 'AH0'], ['B', 'IH0', 'G', 'IH1', 'N', 'IH0', 'NG'], ['G', 'AA1', 'D'], ['K', 'R', 'IY0', 'EY1', 'T', 'AH0', 'D'], ['DH', 'AH0'], ['HH', 'EH1', 'V', 'AH0', 'N'], ['AH0', 'N', 'D'], ['DH', 'AH0'], ['ER1', 'TH']] \n",
      "\n",
      "----- Transcribing phonemes to sentences -----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb76230657944299cfbda3dfa62bf7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example English transcription: in the beginning god created the heaven and the earth \n",
      "\n",
      "--- Total Time Elapsed: 17.870779514312744 seconds ---\n",
      "\n",
      "Export/import path matches original values:  True\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "\n",
    "print(\"----- Recompiling Arpabet -----\")\n",
    "file = open(\"bible.txt\")\n",
    "arpabet = arpabet_recompiler(arpabet, file.read())\n",
    "file.close()\n",
    "print(\"\")\n",
    "\n",
    "file = open(\"bible.txt\")\n",
    "data = text_to_sentences(file.read())\n",
    "data = data[:500]\n",
    "arpabet, accepted_words, accepted_phonemes = arpabet_reader('arpabet.pkl')\n",
    "\n",
    "print(\"----- Transcribing sentences to phonemes -----\")\n",
    "p = sentences_to_phonemes(data)\n",
    "print(\"Example phonetic transcription:\", p[0], \"\\n\")\n",
    "\n",
    "print(\"----- Transcribing phonemes to sentences -----\")\n",
    "s = phonemes_to_sentence(p)\n",
    "print(\"Example English transcription:\", s[0],\"\\n\")\n",
    "\n",
    "# close file\n",
    "file.close()\n",
    "\n",
    "print(\"--- Total Time Elapsed: %s seconds ---\\n\" % (time() - start_time))\n",
    "\n",
    "to_json(\"example.json\", p)\n",
    "f = from_json('example.json')\n",
    "print(\"Export/import path matches original values: \", f == p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
